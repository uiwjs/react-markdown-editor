{"version":3,"file":"static/js/1767.f4aa36c5.chunk.js","mappings":"8IAAA,SAASA,EAAQC,GAEf,IADA,IAAIC,EAAI,CAAC,EACAC,EAAI,EAAGC,EAAIH,EAAMI,OAAQF,EAAIC,IAAKD,EAAGD,EAAED,EAAME,KAAM,EAC5D,OAAOD,CACR,C,4CACD,IAAII,EAAWN,EAAQ,CACrB,OACA,SACA,OACA,UACA,QACA,SACA,WACA,OACA,QACA,SACA,QACA,SACA,UACA,SACA,YACA,WACA,SACA,OACA,MACA,WACA,OACA,QACA,OACA,KACA,UACA,QACA,UACA,KACA,SACA,OACA,WACA,SACA,SACA,MACA,SACA,OACA,KACA,WACA,SACA,QACA,QACA,QACA,WACA,YACA,UACA,WACA,UACA,WACA,WACA,QACA,OACA,OACA,SACA,YACA,QACA,UACA,SACA,WACA,aACA,KACA,MACA,UACA,MACA,OAEEO,EAAYP,EAAQ,CAAC,KAAM,WAAW,MAAO,KAAK,KAAK,OAO3D,SAASQ,EAAUC,EAAQC,GACzB,GAAID,EAAOE,WAAY,OAAO,KAC9B,IAwBkBC,EAAOC,EAAQC,EAxB7BC,EAAKN,EAAOO,OAChB,MAAU,KAAND,GAAiB,KAANA,EARjB,SAAeE,EAAQR,EAAQC,GAE7B,OADAA,EAAMQ,SAASC,KAAKF,GACbA,EAAOR,EAAQC,EACvB,CAMUU,EAsBSR,EAtBQG,EAsBDF,EAtBK,SAuBvB,SAASJ,EAAQC,GAEtB,IADA,IAAqBK,EAAjBM,GAAU,EACiB,OAAvBN,EAAKN,EAAOO,SAAiB,CACnC,GAAID,GAAMH,IAAUE,IAAcO,GAAU,CAC1CX,EAAMQ,SAASI,MACf,KACD,CACDD,GAAWA,GAAiB,KAANN,CACvB,CACD,OAAOF,CACR,GAjCwCJ,EAAQC,GAChC,KAANK,GAAWN,EAAOc,IAAI,MAC/Bd,EAAOe,YACA,WACQ,KAANT,GAAWN,EAAOc,IAAI,KACxB,WACE,QAAQE,KAAKV,IACtBN,EAAOiB,SAAS,iBAChBjB,EAAOc,IAAI,UACJ,YACE,eAAeE,KAAKV,IAC7BN,EAAOiB,SAAS,gBAChBjB,EAAOc,IAAI,UACJ,YACE,iBAAiBE,KAAKV,IAC/BN,EAAOiB,SAAS,kBACT,YAEA,IAEV,CAgBM,IAAMC,EAAS,CACpBC,WAAY,WACV,MAAO,CAACV,SAAU,CAACV,GACpB,EAEDqB,MAAO,SAASpB,EAAQC,GACtB,IAAIG,EAAQH,EAAMQ,SAASR,EAAMQ,SAASb,OAAO,GAAGI,EAAQC,GAC5D,GAAa,YAATG,EAAqB,CACvB,IAAIiB,EAAOrB,EAAOsB,UAClBlB,EAAQP,EAAS0B,qBAAqBvB,EAAOsB,WAAa,UACtDxB,EAAUyB,qBAAqBvB,EAAOsB,WAAa,WACnD,qBAAqBN,KAAKK,GAAQ,MAClC,iBAAiBL,KAAKK,IACtB,iBAAiBL,KAAKK,IACtB,uBAAuBL,KAAKK,IAC5B,uCAAuCL,KAAKK,IAC5C,YAAYL,KAAKK,GAJa,SAK9B,UACL,CACD,OAAOjB,CACR,EACDoB,aAAc,CACZC,cAAe,CAACC,KAAM,O","sources":["../node_modules/@codemirror/legacy-modes/mode/eiffel.js"],"sourcesContent":["function wordObj(words) {\n  var o = {};\n  for (var i = 0, e = words.length; i < e; ++i) o[words[i]] = true;\n  return o;\n}\nvar keywords = wordObj([\n  'note',\n  'across',\n  'when',\n  'variant',\n  'until',\n  'unique',\n  'undefine',\n  'then',\n  'strip',\n  'select',\n  'retry',\n  'rescue',\n  'require',\n  'rename',\n  'reference',\n  'redefine',\n  'prefix',\n  'once',\n  'old',\n  'obsolete',\n  'loop',\n  'local',\n  'like',\n  'is',\n  'inspect',\n  'infix',\n  'include',\n  'if',\n  'frozen',\n  'from',\n  'external',\n  'export',\n  'ensure',\n  'end',\n  'elseif',\n  'else',\n  'do',\n  'creation',\n  'create',\n  'check',\n  'alias',\n  'agent',\n  'separate',\n  'invariant',\n  'inherit',\n  'indexing',\n  'feature',\n  'expanded',\n  'deferred',\n  'class',\n  'Void',\n  'True',\n  'Result',\n  'Precursor',\n  'False',\n  'Current',\n  'create',\n  'attached',\n  'detachable',\n  'as',\n  'and',\n  'implies',\n  'not',\n  'or'\n]);\nvar operators = wordObj([\":=\", \"and then\",\"and\", \"or\",\"<<\",\">>\"]);\n\nfunction chain(newtok, stream, state) {\n  state.tokenize.push(newtok);\n  return newtok(stream, state);\n}\n\nfunction tokenBase(stream, state) {\n  if (stream.eatSpace()) return null;\n  var ch = stream.next();\n  if (ch == '\"'||ch == \"'\") {\n    return chain(readQuoted(ch, \"string\"), stream, state);\n  } else if (ch == \"-\"&&stream.eat(\"-\")) {\n    stream.skipToEnd();\n    return \"comment\";\n  } else if (ch == \":\"&&stream.eat(\"=\")) {\n    return \"operator\";\n  } else if (/[0-9]/.test(ch)) {\n    stream.eatWhile(/[xXbBCc0-9\\.]/);\n    stream.eat(/[\\?\\!]/);\n    return \"variable\";\n  } else if (/[a-zA-Z_0-9]/.test(ch)) {\n    stream.eatWhile(/[a-zA-Z_0-9]/);\n    stream.eat(/[\\?\\!]/);\n    return \"variable\";\n  } else if (/[=+\\-\\/*^%<>~]/.test(ch)) {\n    stream.eatWhile(/[=+\\-\\/*^%<>~]/);\n    return \"operator\";\n  } else {\n    return null;\n  }\n}\n\nfunction readQuoted(quote, style,  unescaped) {\n  return function(stream, state) {\n    var escaped = false, ch;\n    while ((ch = stream.next()) != null) {\n      if (ch == quote && (unescaped || !escaped)) {\n        state.tokenize.pop();\n        break;\n      }\n      escaped = !escaped && ch == \"%\";\n    }\n    return style;\n  };\n}\n\nexport const eiffel = {\n  startState: function() {\n    return {tokenize: [tokenBase]};\n  },\n\n  token: function(stream, state) {\n    var style = state.tokenize[state.tokenize.length-1](stream, state);\n    if (style == \"variable\") {\n      var word = stream.current();\n      style = keywords.propertyIsEnumerable(stream.current()) ? \"keyword\"\n        : operators.propertyIsEnumerable(stream.current()) ? \"operator\"\n        : /^[A-Z][A-Z_0-9]*$/g.test(word) ? \"tag\"\n        : /^0[bB][0-1]+$/g.test(word) ? \"number\"\n        : /^0[cC][0-7]+$/g.test(word) ? \"number\"\n        : /^0[xX][a-fA-F0-9]+$/g.test(word) ? \"number\"\n        : /^([0-9]+\\.[0-9]*)|([0-9]*\\.[0-9]+)$/g.test(word) ? \"number\"\n        : /^[0-9]+$/g.test(word) ? \"number\"\n        : \"variable\";\n    }\n    return style;\n  },\n  languageData: {\n    commentTokens: {line: \"--\"}\n  }\n};\n\n"],"names":["wordObj","words","o","i","e","length","keywords","operators","tokenBase","stream","state","eatSpace","quote","style","unescaped","ch","next","newtok","tokenize","push","chain","escaped","pop","eat","skipToEnd","test","eatWhile","eiffel","startState","token","word","current","propertyIsEnumerable","languageData","commentTokens","line"],"sourceRoot":""}