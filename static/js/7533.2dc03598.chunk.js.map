{"version":3,"file":"static/js/7533.2dc03598.chunk.js","mappings":"0JAAA,IAAIA,EAAa,QAEjB,SAASC,EAAWC,GAClB,OAAO,IAAIC,OAAO,MAAQD,EAAME,KAAK,OAAS,QAChD,CAEA,IAAIC,EAAY,mHACZC,EAAa,gCACbC,EAAc,4BACdC,EAAS,6BAETC,EAAgBR,EAAW,CAAC,MAAO,KAAM,MACb,KAAM,OAAQ,KACd,aAAc,WAC1CS,EAAiB,CAAC,MAAO,QAAS,OAAQ,KAAM,SAAU,OACxC,SAAU,MAAO,QAAS,UAAW,SAKvDC,EAAWV,EAAWS,EAAeE,OAJpB,CAAC,QAAS,KAAM,WAAY,WAAY,SACvC,KAAM,KAAM,KAAM,MAAO,SAAU,OACnC,OAAQ,IAAK,QAAS,OAAQ,QAAS,aAI7DF,EAAiBT,EAAWS,GAG5B,IAAIG,EAAiB,sBACjBC,EAAgB,cAEhBC,EAAYd,EADM,CAAC,WAAY,MAAO,YAAa,OAAQ,OAAQ,QAAS,KAAM,MAAO,MAAO,OAIpG,SAASe,EAAUC,EAAQC,GAEzB,GAAID,EAAOE,MAAO,CACU,OAAtBD,EAAME,MAAMC,QAAgBH,EAAME,MAAMC,OAAQ,GACpD,IAAIC,EAAcJ,EAAME,MAAMG,OAC9B,GAAIN,EAAOO,WAAY,CACrB,IAAIC,EAAaR,EAAOS,cACxB,OAAID,EAAaH,GAAmC,UAApBJ,EAAME,MAAMO,KACnC,SACEF,EAAaH,EACf,SAEF,IACT,CACMA,EAAc,GAChBM,EAAOX,EAAQC,EAGrB,CACA,GAAID,EAAOO,WACT,OAAO,KAGT,IAAIK,EAAKZ,EAAOa,OAGhB,GAAIb,EAAOc,MAAM,QAEf,OADAd,EAAOe,YACA,UAIT,GAAIf,EAAOc,MAAM,OAEf,OADAb,EAAMe,SAAWC,EACVhB,EAAMe,SAAShB,EAAQC,GAIhC,GAAW,MAAPW,EAEF,OADAZ,EAAOe,YACA,UAIT,GAAIf,EAAOc,MAAM,cAAc,GAAQ,CACrC,IAAII,GAAe,EAYnB,GAVIlB,EAAOc,MAAM,gCACfI,GAAe,GAEblB,EAAOc,MAAM,iBACfI,GAAe,GAEblB,EAAOc,MAAM,cACfI,GAAe,GAGbA,EAKF,MAHqB,KAAjBlB,EAAOa,QACTb,EAAOmB,OAAO,GAET,SAGT,IAAIC,GAAa,EAajB,GAXIpB,EAAOc,MAAM,qBACfM,GAAa,GAGXpB,EAAOc,MAAM,+BACfM,GAAa,GAGXpB,EAAOc,MAAM,oBACfM,GAAa,GAEXA,EACF,MAAO,QAEX,CAGA,GAAIpB,EAAOc,MAAMlB,GAEf,OADAK,EAAMe,SAAWK,EAAarB,EAAOsB,WAAW,EAAO,UAChDrB,EAAMe,SAAShB,EAAQC,GAGhC,GAAID,EAAOc,MAAMjB,GAAgB,CAC/B,GAAwB,KAApBG,EAAOsB,WAAoBtB,EAAOc,MAAM,SAAS,GAEnD,OADAb,EAAMe,SAAWK,EAAarB,EAAOsB,WAAW,EAAM,kBAC/CrB,EAAMe,SAAShB,EAAQC,GAE9BD,EAAOmB,OAAO,EAElB,CAKA,OAAInB,EAAOc,MAAM1B,IAAcY,EAAOc,MAAMtB,GACnC,WAELQ,EAAOc,MAAMzB,GACR,cAGLW,EAAOc,MAAMhB,GACR,OAGLE,EAAOc,MAAMvB,IAAWU,EAAMsB,MAAQvB,EAAOc,MAAMxB,GAC9C,WAGLU,EAAOc,MAAMpB,GACR,UAGLM,EAAOc,MAAMxB,GACR,YAITU,EAAOwB,OACAzC,EACT,CAEA,SAASsC,EAAaI,EAAWC,EAAYC,GAC3C,OAAO,SAAS3B,EAAQC,GACtB,MAAQD,EAAO4B,OAEb,GADA5B,EAAO6B,SAAS,aACZ7B,EAAO8B,IAAI,OAEb,GADA9B,EAAOwB,OACHE,GAAc1B,EAAO4B,MACvB,OAAOD,MAEJ,IAAI3B,EAAOc,MAAMW,GAEtB,OADAxB,EAAMe,SAAWjB,EACV4B,EAEP3B,EAAO8B,IAAI,SACb,CAKF,OAHIJ,IACFzB,EAAMe,SAAWjB,GAEZ4B,CACT,CACF,CAEA,SAASV,EAAYjB,EAAQC,GAC3B,MAAQD,EAAO4B,OAAO,CAEpB,GADA5B,EAAO6B,SAAS,QACZ7B,EAAOc,MAAM,OAAQ,CACvBb,EAAMe,SAAWjB,EACjB,KACF,CACAC,EAAO6B,SAAS,IAClB,CACA,MAAO,SACT,CAEA,SAASE,EAAO/B,EAAQC,GAEtB,IAF8C,IAAjBS,EAAIsB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,SAChC1B,EAAS,EAAGF,GAAQ,EAAO+B,EAAc,KACpChC,EAAQF,EAAME,MAAOA,EAAOA,EAAQA,EAAMiC,KACjD,GAAmB,WAAfjC,EAAMO,MAAmC,KAAdP,EAAMO,KAAa,CAChDJ,EAASH,EAAMG,OAASN,EAAOqC,WAC/B,KACF,CAEW,WAAT3B,GACFN,EAAQ,KACR+B,EAAcnC,EAAOsC,SAAWtC,EAAOsB,UAAUW,QACxChC,EAAME,MAAMC,QACrBH,EAAME,MAAMC,OAAQ,GAEtBH,EAAME,MAAQ,CACZG,OAAQA,EACRI,KAAMA,EACN0B,KAAMnC,EAAME,MACZC,MAAOA,EACP+B,YAAaA,EAEjB,CAEA,SAASxB,EAAOX,EAAQC,GACtB,GAAKA,EAAME,MAAMiC,KAAjB,CACA,GAAyB,WAArBnC,EAAME,MAAMO,KAAmB,CAGjC,IAFA,IAAI6B,EAAUvC,EAAOS,cACjB+B,GAAU,EACLrC,EAAQF,EAAME,MAAOA,EAAOA,EAAQA,EAAMiC,KACjD,GAAIG,IAAYpC,EAAMG,OAAQ,CAC5BkC,GAAU,EACV,KACF,CAEF,IAAKA,EACH,OAAO,EAET,KAAOvC,EAAME,MAAMiC,MAAQnC,EAAME,MAAMG,SAAWiC,GAChDtC,EAAME,MAAQF,EAAME,MAAMiC,KAE5B,OAAO,CACT,CAEE,OADAnC,EAAME,MAAQF,EAAME,MAAMiC,MACnB,CAnBoB,CAqB/B,CA+CO,IAAMK,EAAe,CAC1BC,KAAM,eACNC,WAAY,WACV,MAAO,CACL3B,SAAUjB,EACVI,MAAO,CAACG,OAAQ,EAAGI,KAAK,SAAU0B,KAAM,KAAMhC,OAAO,GACrDmB,MAAM,EACNZ,OAAQ,EAEZ,EAEAiC,MAAO,SAAS5C,EAAQC,GACtB,IAAI4C,EAAkC,OAAtB5C,EAAME,MAAMC,OAAkBH,EAAME,MAChD0C,GAAa7C,EAAOE,QAAO2C,EAAUzC,OAAQ,GAEjD,IAAI0C,EA5DR,SAAoB9C,EAAQC,GAC1B,IAAI6C,EAAQ7C,EAAMe,SAAShB,EAAQC,GAC/BqB,EAAUtB,EAAOsB,UAGL,WAAZA,IACFrB,EAAMU,QAAS,KAEC,OAAZW,GAAgC,OAAZA,IAAqBtB,EAAO4B,OACrC,WAAVkB,IACLf,EAAO/B,EAAQC,GAEjB,IAAI8C,EAAkB,MAAMC,QAAQ1B,GAYpC,IAXyB,IAArByB,GACFhB,EAAO/B,EAAQC,EAAO,MAAMgD,MAAMF,EAAiBA,EAAgB,IAEjEtD,EAAeyD,KAAK5B,IACtBS,EAAO/B,EAAQC,GAEF,QAAXqB,GACFX,EAAOX,EAAQC,GAIH,WAAV6C,GACEnC,EAAOX,EAAQC,GACjB,OAAOlB,EAIX,IAAyB,KADzBgE,EAAkB,MAAMC,QAAQ1B,IACJ,CAC1B,KAA2B,UAApBrB,EAAME,MAAMO,MAAoBT,EAAME,MAAMiC,MACjDnC,EAAME,MAAQF,EAAME,MAAMiC,KACxBnC,EAAME,MAAMO,MAAQY,IACtBrB,EAAME,MAAQF,EAAME,MAAMiC,KAC9B,CAOA,OANInC,EAAMU,QAAUX,EAAO4B,QACD,UAApB3B,EAAME,MAAMO,MAAoBT,EAAME,MAAMiC,OAC9CnC,EAAME,MAAQF,EAAME,MAAMiC,MAC5BnC,EAAMU,QAAS,GAGD,UAATmC,GAA8B,UAATA,EAAoB,KAAOA,CACzD,CAiBgBK,CAAWnD,EAAQC,GAM/B,OALI6C,GAAkB,WAATA,IACPD,IAAWA,EAAUzC,OAAQ,GACjCH,EAAMsB,KAAgB,eAATuB,GAA8C,KAApB9C,EAAOsB,WAGzCwB,CACT,EAEAf,OAAQ,SAAS9B,EAAOmD,GACtB,GAAInD,EAAMe,UAAYjB,EAAW,OAAO,EACxC,IAAII,EAAQF,EAAME,MACdkD,EAASD,GAAQ,MAAMJ,QAAQI,EAAKE,OAAO,KAAO,EACtD,GAAID,EAAQ,KAAqB,UAAdlD,EAAMO,MAAoBP,EAAMiC,MAAMjC,EAAQA,EAAMiC,KACvE,IAAImB,EAASF,GAAUlD,EAAMO,OAAS0C,EAAKE,OAAO,GAClD,OAAInD,EAAMC,MACDD,EAAMgC,aAAeoB,EAAS,EAAI,IAEjCA,EAASpD,EAAMiC,KAAOjC,GAAOG,MACzC,EAEAkD,aAAc,CACZC,cAAe,CAACC,KAAM,M","sources":["../../node_modules/@codemirror/legacy-modes/mode/coffeescript.js"],"sourcesContent":["var ERRORCLASS = \"error\";\n\nfunction wordRegexp(words) {\n  return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n}\n\nvar operators = /^(?:->|=>|\\+[+=]?|-[\\-=]?|\\*[\\*=]?|\\/[\\/=]?|[=!]=|<[><]?=?|>>?=?|%=?|&=?|\\|=?|\\^=?|\\~|!|\\?|(or|and|\\|\\||&&|\\?)=)/;\nvar delimiters = /^(?:[()\\[\\]{},:`=;]|\\.\\.?\\.?)/;\nvar identifiers = /^[_A-Za-z$][_A-Za-z$0-9]*/;\nvar atProp = /^@[_A-Za-z$][_A-Za-z$0-9]*/;\n\nvar wordOperators = wordRegexp([\"and\", \"or\", \"not\",\n                                \"is\", \"isnt\", \"in\",\n                                \"instanceof\", \"typeof\"]);\nvar indentKeywords = [\"for\", \"while\", \"loop\", \"if\", \"unless\", \"else\",\n                      \"switch\", \"try\", \"catch\", \"finally\", \"class\"];\nvar commonKeywords = [\"break\", \"by\", \"continue\", \"debugger\", \"delete\",\n                      \"do\", \"in\", \"of\", \"new\", \"return\", \"then\",\n                      \"this\", \"@\", \"throw\", \"when\", \"until\", \"extends\"];\n\nvar keywords = wordRegexp(indentKeywords.concat(commonKeywords));\n\nindentKeywords = wordRegexp(indentKeywords);\n\n\nvar stringPrefixes = /^('{3}|\\\"{3}|['\\\"])/;\nvar regexPrefixes = /^(\\/{3}|\\/)/;\nvar commonConstants = [\"Infinity\", \"NaN\", \"undefined\", \"null\", \"true\", \"false\", \"on\", \"off\", \"yes\", \"no\"];\nvar constants = wordRegexp(commonConstants);\n\n// Tokenizers\nfunction tokenBase(stream, state) {\n  // Handle scope changes\n  if (stream.sol()) {\n    if (state.scope.align === null) state.scope.align = false;\n    var scopeOffset = state.scope.offset;\n    if (stream.eatSpace()) {\n      var lineOffset = stream.indentation();\n      if (lineOffset > scopeOffset && state.scope.type == \"coffee\") {\n        return \"indent\";\n      } else if (lineOffset < scopeOffset) {\n        return \"dedent\";\n      }\n      return null;\n    } else {\n      if (scopeOffset > 0) {\n        dedent(stream, state);\n      }\n    }\n  }\n  if (stream.eatSpace()) {\n    return null;\n  }\n\n  var ch = stream.peek();\n\n  // Handle docco title comment (single line)\n  if (stream.match(\"####\")) {\n    stream.skipToEnd();\n    return \"comment\";\n  }\n\n  // Handle multi line comments\n  if (stream.match(\"###\")) {\n    state.tokenize = longComment;\n    return state.tokenize(stream, state);\n  }\n\n  // Single line comment\n  if (ch === \"#\") {\n    stream.skipToEnd();\n    return \"comment\";\n  }\n\n  // Handle number literals\n  if (stream.match(/^-?[0-9\\.]/, false)) {\n    var floatLiteral = false;\n    // Floats\n    if (stream.match(/^-?\\d*\\.\\d+(e[\\+\\-]?\\d+)?/i)) {\n      floatLiteral = true;\n    }\n    if (stream.match(/^-?\\d+\\.\\d*/)) {\n      floatLiteral = true;\n    }\n    if (stream.match(/^-?\\.\\d+/)) {\n      floatLiteral = true;\n    }\n\n    if (floatLiteral) {\n      // prevent from getting extra . on 1..\n      if (stream.peek() == \".\"){\n        stream.backUp(1);\n      }\n      return \"number\";\n    }\n    // Integers\n    var intLiteral = false;\n    // Hex\n    if (stream.match(/^-?0x[0-9a-f]+/i)) {\n      intLiteral = true;\n    }\n    // Decimal\n    if (stream.match(/^-?[1-9]\\d*(e[\\+\\-]?\\d+)?/)) {\n      intLiteral = true;\n    }\n    // Zero by itself with no other piece of number.\n    if (stream.match(/^-?0(?![\\dx])/i)) {\n      intLiteral = true;\n    }\n    if (intLiteral) {\n      return \"number\";\n    }\n  }\n\n  // Handle strings\n  if (stream.match(stringPrefixes)) {\n    state.tokenize = tokenFactory(stream.current(), false, \"string\");\n    return state.tokenize(stream, state);\n  }\n  // Handle regex literals\n  if (stream.match(regexPrefixes)) {\n    if (stream.current() != \"/\" || stream.match(/^.*\\//, false)) { // prevent highlight of division\n      state.tokenize = tokenFactory(stream.current(), true, \"string.special\");\n      return state.tokenize(stream, state);\n    } else {\n      stream.backUp(1);\n    }\n  }\n\n\n\n  // Handle operators and delimiters\n  if (stream.match(operators) || stream.match(wordOperators)) {\n    return \"operator\";\n  }\n  if (stream.match(delimiters)) {\n    return \"punctuation\";\n  }\n\n  if (stream.match(constants)) {\n    return \"atom\";\n  }\n\n  if (stream.match(atProp) || state.prop && stream.match(identifiers)) {\n    return \"property\";\n  }\n\n  if (stream.match(keywords)) {\n    return \"keyword\";\n  }\n\n  if (stream.match(identifiers)) {\n    return \"variable\";\n  }\n\n  // Handle non-detected items\n  stream.next();\n  return ERRORCLASS;\n}\n\nfunction tokenFactory(delimiter, singleline, outclass) {\n  return function(stream, state) {\n    while (!stream.eol()) {\n      stream.eatWhile(/[^'\"\\/\\\\]/);\n      if (stream.eat(\"\\\\\")) {\n        stream.next();\n        if (singleline && stream.eol()) {\n          return outclass;\n        }\n      } else if (stream.match(delimiter)) {\n        state.tokenize = tokenBase;\n        return outclass;\n      } else {\n        stream.eat(/['\"\\/]/);\n      }\n    }\n    if (singleline) {\n      state.tokenize = tokenBase;\n    }\n    return outclass;\n  };\n}\n\nfunction longComment(stream, state) {\n  while (!stream.eol()) {\n    stream.eatWhile(/[^#]/);\n    if (stream.match(\"###\")) {\n      state.tokenize = tokenBase;\n      break;\n    }\n    stream.eatWhile(\"#\");\n  }\n  return \"comment\";\n}\n\nfunction indent(stream, state, type = \"coffee\") {\n  var offset = 0, align = false, alignOffset = null;\n  for (var scope = state.scope; scope; scope = scope.prev) {\n    if (scope.type === \"coffee\" || scope.type == \"}\") {\n      offset = scope.offset + stream.indentUnit;\n      break;\n    }\n  }\n  if (type !== \"coffee\") {\n    align = null;\n    alignOffset = stream.column() + stream.current().length;\n  } else if (state.scope.align) {\n    state.scope.align = false;\n  }\n  state.scope = {\n    offset: offset,\n    type: type,\n    prev: state.scope,\n    align: align,\n    alignOffset: alignOffset\n  };\n}\n\nfunction dedent(stream, state) {\n  if (!state.scope.prev) return;\n  if (state.scope.type === \"coffee\") {\n    var _indent = stream.indentation();\n    var matched = false;\n    for (var scope = state.scope; scope; scope = scope.prev) {\n      if (_indent === scope.offset) {\n        matched = true;\n        break;\n      }\n    }\n    if (!matched) {\n      return true;\n    }\n    while (state.scope.prev && state.scope.offset !== _indent) {\n      state.scope = state.scope.prev;\n    }\n    return false;\n  } else {\n    state.scope = state.scope.prev;\n    return false;\n  }\n}\n\nfunction tokenLexer(stream, state) {\n  var style = state.tokenize(stream, state);\n  var current = stream.current();\n\n  // Handle scope changes.\n  if (current === \"return\") {\n    state.dedent = true;\n  }\n  if (((current === \"->\" || current === \"=>\") && stream.eol())\n      || style === \"indent\") {\n    indent(stream, state);\n  }\n  var delimiter_index = \"[({\".indexOf(current);\n  if (delimiter_index !== -1) {\n    indent(stream, state, \"])}\".slice(delimiter_index, delimiter_index+1));\n  }\n  if (indentKeywords.exec(current)){\n    indent(stream, state);\n  }\n  if (current == \"then\"){\n    dedent(stream, state);\n  }\n\n\n  if (style === \"dedent\") {\n    if (dedent(stream, state)) {\n      return ERRORCLASS;\n    }\n  }\n  delimiter_index = \"])}\".indexOf(current);\n  if (delimiter_index !== -1) {\n    while (state.scope.type == \"coffee\" && state.scope.prev)\n      state.scope = state.scope.prev;\n    if (state.scope.type == current)\n      state.scope = state.scope.prev;\n  }\n  if (state.dedent && stream.eol()) {\n    if (state.scope.type == \"coffee\" && state.scope.prev)\n      state.scope = state.scope.prev;\n    state.dedent = false;\n  }\n\n  return style == \"indent\" || style == \"dedent\" ? null : style;\n}\n\nexport const coffeeScript = {\n  name: \"coffeescript\",\n  startState: function() {\n    return {\n      tokenize: tokenBase,\n      scope: {offset: 0, type:\"coffee\", prev: null, align: false},\n      prop: false,\n      dedent: 0\n    };\n  },\n\n  token: function(stream, state) {\n    var fillAlign = state.scope.align === null && state.scope;\n    if (fillAlign && stream.sol()) fillAlign.align = false;\n\n    var style = tokenLexer(stream, state);\n    if (style && style != \"comment\") {\n      if (fillAlign) fillAlign.align = true;\n      state.prop = style == \"punctuation\" && stream.current() == \".\"\n    }\n\n    return style;\n  },\n\n  indent: function(state, text) {\n    if (state.tokenize != tokenBase) return 0;\n    var scope = state.scope;\n    var closer = text && \"])}\".indexOf(text.charAt(0)) > -1;\n    if (closer) while (scope.type == \"coffee\" && scope.prev) scope = scope.prev;\n    var closes = closer && scope.type === text.charAt(0);\n    if (scope.align)\n      return scope.alignOffset - (closes ? 1 : 0);\n    else\n      return (closes ? scope.prev : scope).offset;\n  },\n\n  languageData: {\n    commentTokens: {line: \"#\"}\n  }\n};\n"],"names":["ERRORCLASS","wordRegexp","words","RegExp","join","operators","delimiters","identifiers","atProp","wordOperators","indentKeywords","keywords","concat","stringPrefixes","regexPrefixes","constants","tokenBase","stream","state","sol","scope","align","scopeOffset","offset","eatSpace","lineOffset","indentation","type","dedent","ch","peek","match","skipToEnd","tokenize","longComment","floatLiteral","backUp","intLiteral","tokenFactory","current","prop","next","delimiter","singleline","outclass","eol","eatWhile","eat","indent","arguments","length","undefined","alignOffset","prev","indentUnit","column","_indent","matched","coffeeScript","name","startState","token","fillAlign","style","delimiter_index","indexOf","slice","exec","tokenLexer","text","closer","charAt","closes","languageData","commentTokens","line"],"sourceRoot":""}