{"version":3,"file":"static/js/8570.9c1fe492.chunk.js","mappings":"8IAAA,SAASA,EAAMC,GAEb,IADA,IAAIC,EAAM,GAAIF,EAAQC,EAAIE,MAAM,KACvBC,EAAI,EAAGA,EAAIJ,EAAMK,SAAUD,EAAGF,EAAIF,EAAMI,KAAM,EACvD,OAAOF,E,uCAGT,IA+BII,EA/BAC,EAAmB,gJAGjBC,EAAe,CACnBC,SAAUT,EAAM,scAKAO,GAChBG,cAAeV,EAAMO,GACrBI,QAASX,EAAM,uJAEfY,MAAOZ,EAAM,wCACba,MAAO,CACL,IAAK,SAASC,EAAQC,GAEpB,OADAD,EAAOE,SAAS,WACT,UAKTC,EAAsBT,EAAaS,oBACnCR,EAAWD,EAAaC,SACxBE,EAAUH,EAAaG,QACvBD,EAAgBF,EAAaE,cAC7BE,EAAQJ,EAAaI,MACrBC,EAAQL,EAAaK,MACrBK,EAAmBV,EAAaU,iBAChCC,EAAiB,mBAIrB,SAASC,EAAUN,EAAQO,GACzB,IAiDmBC,EAjDfC,EAAKT,EAAOU,OAChB,GAAIX,EAAMU,GAAK,CACb,IAAIE,EAASZ,EAAMU,GAAIT,EAAQO,GAC/B,IAAe,IAAXI,EAAkB,OAAOA,EAE/B,GAAU,KAANF,GAAmB,KAANA,GAAmB,KAANA,EAE5B,OADAF,EAAMK,UA2CWJ,EA3CYC,EA4CxB,SAAST,EAAQO,GAEtB,IADA,IAAqBG,EAAjBG,GAAU,EAAaC,GAAM,EACA,OAAzBJ,EAAOV,EAAOU,SAAiB,CACrC,GAAIA,GAAQF,IAAUK,EAAS,CAACC,GAAM,EAAM,MAC5CD,GAAWA,GAAmB,MAARH,EAIxB,OAFII,IAASD,IAAWT,KACtBG,EAAMK,SAAW,MACZ,WAnDAL,EAAMK,SAASZ,EAAQO,GAEhC,GAAI,qBAAqBQ,KAAKN,GAE5B,OADAjB,EAAUiB,EACH,KAET,GAAI,KAAKM,KAAKN,GAEZ,OADAT,EAAOE,SAAS,UACT,SAET,GAAU,KAANO,EAAW,CACb,GAAIT,EAAOgB,IAAI,KAEb,OADAT,EAAMK,SAAWK,EACVA,EAAmBjB,EAAQO,GAEpC,GAAIP,EAAOgB,IAAI,KAEb,OADAT,EAAMK,SAAWM,EACVA,EAAalB,EAAQO,GAE9B,GAAIP,EAAOgB,IAAI,KAEb,OADAhB,EAAOmB,YACA,UAGX,GAAId,EAAeU,KAAKN,GAEtB,OADAT,EAAOE,SAASG,GACT,WAETL,EAAOE,SAAS,sBAChB,IAAIkB,EAAMpB,EAAOqB,UACjB,OAAI1B,EAAS2B,qBAAqBF,IAC5BxB,EAAc0B,qBAAqBF,KAAM5B,EAAU,gBAChD,WAELK,EAAQyB,qBAAqBF,IAC3BxB,EAAc0B,qBAAqBF,KAAM5B,EAAU,gBAChD,WAELM,EAAMwB,qBAAqBF,GAAa,OACrC,WAgBT,SAASF,EAAalB,EAAQO,GAE5B,IADA,IAAsBE,EAAlBc,GAAW,EACRd,EAAKT,EAAOU,QAAQ,CACzB,GAAU,KAAND,GAAac,EAAU,CACzBhB,EAAMK,SAAW,KACjB,MAEFW,EAAkB,KAANd,EAEd,MAAO,UAGT,SAASQ,EAAmBjB,EAAQO,GAElC,IADA,IAAsBE,EAAlBc,GAAW,EACRd,EAAKT,EAAOU,QAAQ,CACzB,GAAU,KAAND,GAAac,EAAU,CACzBhB,EAAMK,SAAW,KACjB,MAEFW,EAAkB,KAANd,EAEd,MAAO,UAGT,SAASe,EAAQC,EAAUC,EAAQC,EAAMC,EAAOC,GAC9CC,KAAKL,SAAWA,EAChBK,KAAKJ,OAASA,EACdI,KAAKH,KAAOA,EACZG,KAAKF,MAAQA,EACbE,KAAKD,KAAOA,EAEd,SAASE,EAAYxB,EAAOyB,EAAKL,GAC/B,IAAIM,EAAS1B,EAAMkB,SAGnB,OAFIlB,EAAM2B,SAAiC,aAAtB3B,EAAM2B,QAAQP,OACjCM,EAAS1B,EAAM2B,QAAQT,UAClBlB,EAAM2B,QAAU,IAAIV,EAAQS,EAAQD,EAAKL,EAAM,KAAMpB,EAAM2B,SAEpE,SAASC,EAAW5B,GAClB,IAAI6B,EAAI7B,EAAM2B,QAAQP,KAGtB,MAFS,KAALS,GAAiB,KAALA,GAAiB,KAALA,IAC1B7B,EAAMkB,SAAWlB,EAAM2B,QAAQT,UAC1BlB,EAAM2B,QAAU3B,EAAM2B,QAAQL,KAKhC,IAAMQ,EAAI,CACfC,WAAY,SAASC,GACnB,MAAO,CACL3B,SAAU,KACVsB,QAAS,IAAIV,GAASe,EAAY,EAAG,OAAO,GAC5Cd,SAAU,EACVe,aAAa,IAIjBC,MAAO,SAASzC,EAAQO,GACtB,IAAImC,EAAMnC,EAAM2B,QAMhB,GALIlC,EAAO2C,QACQ,MAAbD,EAAId,QAAec,EAAId,OAAQ,GACnCrB,EAAMkB,SAAWzB,EAAO4C,cACxBrC,EAAMiC,aAAc,GAElBxC,EAAO6C,WAAY,OAAO,KAC9BrD,EAAU,KACV,IAAIsD,GAASvC,EAAMK,UAAYN,GAAWN,EAAQO,GAClD,GAAa,WAATuC,GAA+B,QAATA,EAAiB,OAAOA,EAGlD,GAFiB,MAAbJ,EAAId,QAAec,EAAId,OAAQ,GAEnB,KAAXpC,GAA6B,KAAXA,GAA6B,KAAXA,GAA+B,aAAZkD,EAAIf,KAC3D,GAAe,KAAXnC,EAAgBuC,EAAYxB,EAAOP,EAAO0B,SAAU,UACxD,GAAe,KAAXlC,EAAgBuC,EAAYxB,EAAOP,EAAO0B,SAAU,UACxD,GAAe,KAAXlC,EAAgBuC,EAAYxB,EAAOP,EAAO0B,SAAU,UACxD,GAAe,KAAXlC,EAAgB,CACvB,KAAmB,aAAZkD,EAAIf,MAAqBe,EAAMP,EAAW5B,GAEjD,IADgB,KAAZmC,EAAIf,OAAae,EAAMP,EAAW5B,IACnB,aAAZmC,EAAIf,MAAqBe,EAAMP,EAAW5B,QAE1Cf,GAAWkD,EAAIf,KAAMQ,EAAW5B,KAClB,KAAZmC,EAAIf,MAA2B,OAAZe,EAAIf,OAA6B,KAAXnC,GAAgC,aAAZkD,EAAIf,MAAkC,gBAAXnC,IACjGuC,EAAYxB,EAAOP,EAAO0B,SAAU,kBAX+CS,EAAW5B,GAahG,OADAA,EAAMiC,aAAc,EACbM,GAGTb,OAAQ,SAAS1B,EAAOwC,EAAWC,GACjC,GAAIzC,EAAMK,UAAYN,GAA+B,MAAlBC,EAAMK,SAAkB,OAAO,KAClE,IAAI8B,EAAMnC,EAAM2B,QAASe,EAAYF,GAAaA,EAAUG,OAAO,GACnD,aAAZR,EAAIf,MAAoC,KAAbsB,IAAkBP,EAAMA,EAAIb,MAC3D,IAAIsB,EAAUF,GAAaP,EAAIf,KAC/B,MAAgB,aAAZe,EAAIf,KAA4Be,EAAIjB,UAAyB,KAAbwB,EAAmB,EAAI9C,GAAuB6C,EAAGI,MAC5FV,EAAId,MAAcc,EAAIhB,QAAUyB,EAAU,EAAI,GAC3CT,EAAIjB,UAAY0B,EAAU,EAAIH,EAAGI,OAG/CC,aAAc,CACZC,cAAe,YACfC,cAAe,CAACC,KAAM,KAAMC,MAAO,CAACC,KAAM,KAAMC,MAAO","sources":["../node_modules/@codemirror/legacy-modes/mode/d.js"],"sourcesContent":["function words(str) {\n  var obj = {}, words = str.split(\" \");\n  for (var i = 0; i < words.length; ++i) obj[words[i]] = true;\n  return obj;\n}\n\nvar blockKeywordsStr = \"body catch class do else enum for foreach foreach_reverse if in interface mixin \" +\n    \"out scope struct switch try union unittest version while with\";\n\nconst parserConfig = {\n  keywords: words(\"abstract alias align asm assert auto break case cast cdouble cent cfloat const continue \" +\n                  \"debug default delegate delete deprecated export extern final finally function goto immutable \" +\n                  \"import inout invariant is lazy macro module new nothrow override package pragma private \" +\n                  \"protected public pure ref return shared short static super synchronized template this \" +\n                  \"throw typedef typeid typeof volatile __FILE__ __LINE__ __gshared __traits __vector __parameters \" +\n                  blockKeywordsStr),\n  blockKeywords: words(blockKeywordsStr),\n  builtin: words(\"bool byte char creal dchar double float idouble ifloat int ireal long real short ubyte \" +\n                 \"ucent uint ulong ushort wchar wstring void size_t sizediff_t\"),\n  atoms: words(\"exit failure success true false null\"),\n  hooks: {\n    \"@\": function(stream, _state) {\n      stream.eatWhile(/[\\w\\$_]/);\n      return \"meta\";\n    }\n  }\n}\n\nvar statementIndentUnit = parserConfig.statementIndentUnit,\n    keywords = parserConfig.keywords,\n    builtin = parserConfig.builtin,\n    blockKeywords = parserConfig.blockKeywords,\n    atoms = parserConfig.atoms,\n    hooks = parserConfig.hooks,\n    multiLineStrings = parserConfig.multiLineStrings;\nvar isOperatorChar = /[+\\-*&%=<>!?|\\/]/;\n\nvar curPunc;\n\nfunction tokenBase(stream, state) {\n  var ch = stream.next();\n  if (hooks[ch]) {\n    var result = hooks[ch](stream, state);\n    if (result !== false) return result;\n  }\n  if (ch == '\"' || ch == \"'\" || ch == \"`\") {\n    state.tokenize = tokenString(ch);\n    return state.tokenize(stream, state);\n  }\n  if (/[\\[\\]{}\\(\\),;\\:\\.]/.test(ch)) {\n    curPunc = ch;\n    return null;\n  }\n  if (/\\d/.test(ch)) {\n    stream.eatWhile(/[\\w\\.]/);\n    return \"number\";\n  }\n  if (ch == \"/\") {\n    if (stream.eat(\"+\")) {\n      state.tokenize = tokenNestedComment;\n      return tokenNestedComment(stream, state);\n    }\n    if (stream.eat(\"*\")) {\n      state.tokenize = tokenComment;\n      return tokenComment(stream, state);\n    }\n    if (stream.eat(\"/\")) {\n      stream.skipToEnd();\n      return \"comment\";\n    }\n  }\n  if (isOperatorChar.test(ch)) {\n    stream.eatWhile(isOperatorChar);\n    return \"operator\";\n  }\n  stream.eatWhile(/[\\w\\$_\\xa1-\\uffff]/);\n  var cur = stream.current();\n  if (keywords.propertyIsEnumerable(cur)) {\n    if (blockKeywords.propertyIsEnumerable(cur)) curPunc = \"newstatement\";\n    return \"keyword\";\n  }\n  if (builtin.propertyIsEnumerable(cur)) {\n    if (blockKeywords.propertyIsEnumerable(cur)) curPunc = \"newstatement\";\n    return \"builtin\";\n  }\n  if (atoms.propertyIsEnumerable(cur)) return \"atom\";\n  return \"variable\";\n}\n\nfunction tokenString(quote) {\n  return function(stream, state) {\n    var escaped = false, next, end = false;\n    while ((next = stream.next()) != null) {\n      if (next == quote && !escaped) {end = true; break;}\n      escaped = !escaped && next == \"\\\\\";\n    }\n    if (end || !(escaped || multiLineStrings))\n      state.tokenize = null;\n    return \"string\";\n  };\n}\n\nfunction tokenComment(stream, state) {\n  var maybeEnd = false, ch;\n  while (ch = stream.next()) {\n    if (ch == \"/\" && maybeEnd) {\n      state.tokenize = null;\n      break;\n    }\n    maybeEnd = (ch == \"*\");\n  }\n  return \"comment\";\n}\n\nfunction tokenNestedComment(stream, state) {\n  var maybeEnd = false, ch;\n  while (ch = stream.next()) {\n    if (ch == \"/\" && maybeEnd) {\n      state.tokenize = null;\n      break;\n    }\n    maybeEnd = (ch == \"+\");\n  }\n  return \"comment\";\n}\n\nfunction Context(indented, column, type, align, prev) {\n  this.indented = indented;\n  this.column = column;\n  this.type = type;\n  this.align = align;\n  this.prev = prev;\n}\nfunction pushContext(state, col, type) {\n  var indent = state.indented;\n  if (state.context && state.context.type == \"statement\")\n    indent = state.context.indented;\n  return state.context = new Context(indent, col, type, null, state.context);\n}\nfunction popContext(state) {\n  var t = state.context.type;\n  if (t == \")\" || t == \"]\" || t == \"}\")\n    state.indented = state.context.indented;\n  return state.context = state.context.prev;\n}\n\n// Interface\n\nexport const d = {\n  startState: function(indentUnit) {\n    return {\n      tokenize: null,\n      context: new Context(-indentUnit, 0, \"top\", false),\n      indented: 0,\n      startOfLine: true\n    };\n  },\n\n  token: function(stream, state) {\n    var ctx = state.context;\n    if (stream.sol()) {\n      if (ctx.align == null) ctx.align = false;\n      state.indented = stream.indentation();\n      state.startOfLine = true;\n    }\n    if (stream.eatSpace()) return null;\n    curPunc = null;\n    var style = (state.tokenize || tokenBase)(stream, state);\n    if (style == \"comment\" || style == \"meta\") return style;\n    if (ctx.align == null) ctx.align = true;\n\n    if ((curPunc == \";\" || curPunc == \":\" || curPunc == \",\") && ctx.type == \"statement\") popContext(state);\n    else if (curPunc == \"{\") pushContext(state, stream.column(), \"}\");\n    else if (curPunc == \"[\") pushContext(state, stream.column(), \"]\");\n    else if (curPunc == \"(\") pushContext(state, stream.column(), \")\");\n    else if (curPunc == \"}\") {\n      while (ctx.type == \"statement\") ctx = popContext(state);\n      if (ctx.type == \"}\") ctx = popContext(state);\n      while (ctx.type == \"statement\") ctx = popContext(state);\n    }\n    else if (curPunc == ctx.type) popContext(state);\n    else if (((ctx.type == \"}\" || ctx.type == \"top\") && curPunc != ';') || (ctx.type == \"statement\" && curPunc == \"newstatement\"))\n      pushContext(state, stream.column(), \"statement\");\n    state.startOfLine = false;\n    return style;\n  },\n\n  indent: function(state, textAfter, cx) {\n    if (state.tokenize != tokenBase && state.tokenize != null) return null;\n    var ctx = state.context, firstChar = textAfter && textAfter.charAt(0);\n    if (ctx.type == \"statement\" && firstChar == \"}\") ctx = ctx.prev;\n    var closing = firstChar == ctx.type;\n    if (ctx.type == \"statement\") return ctx.indented + (firstChar == \"{\" ? 0 : statementIndentUnit || cx.unit);\n    else if (ctx.align) return ctx.column + (closing ? 0 : 1);\n    else return ctx.indented + (closing ? 0 : cx.unit);\n  },\n\n  languageData: {\n    indentOnInput: /^\\s*[{}]$/,\n    commentTokens: {line: \"//\", block: {open: \"/*\", close: \"*/\"}}\n  }\n};\n"],"names":["words","str","obj","split","i","length","curPunc","blockKeywordsStr","parserConfig","keywords","blockKeywords","builtin","atoms","hooks","stream","_state","eatWhile","statementIndentUnit","multiLineStrings","isOperatorChar","tokenBase","state","quote","ch","next","result","tokenize","escaped","end","test","eat","tokenNestedComment","tokenComment","skipToEnd","cur","current","propertyIsEnumerable","maybeEnd","Context","indented","column","type","align","prev","this","pushContext","col","indent","context","popContext","t","d","startState","indentUnit","startOfLine","token","ctx","sol","indentation","eatSpace","style","textAfter","cx","firstChar","charAt","closing","unit","languageData","indentOnInput","commentTokens","line","block","open","close"],"sourceRoot":""}